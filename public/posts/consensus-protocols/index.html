<!doctype html><html lang=en><head><title>Consensus Protocols · memduh</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="memduh"><meta name=description content="A comprehensive overview of consensus protocols in distributed systems, from classical algorithms to modern blockchain consensus mechanisms."><meta name=keywords content="C++,memory,allocators,mmap,slab,performance"><meta name=twitter:card content="summary"><meta name=twitter:title content="Consensus Protocols"><meta name=twitter:description content="A comprehensive overview of consensus protocols in distributed systems, from classical algorithms to modern blockchain consensus mechanisms."><meta property="og:url" content="/posts/consensus-protocols/"><meta property="og:site_name" content="memduh"><meta property="og:title" content="Consensus Protocols"><meta property="og:description" content="A comprehensive overview of consensus protocols in distributed systems, from classical algorithms to modern blockchain consensus mechanisms."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-05-16T11:00:00+03:00"><meta property="article:modified_time" content="2022-05-16T11:00:00+03:00"><link rel=canonical href=/posts/consensus-protocols/><link rel=preload href=/fonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.6445a802b9389c9660e1b07b724dcf5718b1065ed2d71b4eeaf981cc7cc5fc46.css integrity="sha256-ZEWoArk4nJZg4bB7ck3PVxixBl7S1xtO6vmBzHzF/EY=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin=anonymous media=screen><link rel=stylesheet href=/scss/custom.min.0c7feecd432e394a9caa60d61320988a393b7b9a7c0ae204d73b7ce6e142b10c.css integrity="sha256-DH/uzUMuOUqcqmDWEyCYijk7e5p8CuIE1zt85uFCsQw=" crossorigin=anonymous media=screen><link rel=icon type=image/svg+xml href=/images/favicon.svg sizes=any><link rel=icon type=image/png href=/images/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/images/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=/>memduh
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa-solid fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/posts/>posts</a></li><li class=navigation-item><a class=navigation-link href=/notes/>notes</a></li><li class=navigation-item><a class=navigation-link href=/readings/>readings</a></li><li class=navigation-item><a class=navigation-link href=/about/>about</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=/posts/consensus-protocols/>Consensus Protocols</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa-solid fa-calendar" aria-hidden=true></i>
<time datetime=2022-05-16T11:00:00+03:00>May 16, 2022
</time></span><span class=reading-time><i class="fa-solid fa-clock" aria-hidden=true></i>
21-minute read</span></div><div class=categories><i class="fa-solid fa-folder" aria-hidden=true></i>
<a href=/categories/distributed-systems/>Distributed-Systems</a></div></div></header><div class=post-content><h1 id=consensus-protocols>Consensus Protocols
<a class=heading-link href=#consensus-protocols><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><p>Consensus protocols are the backbone of distributed systems, enabling multiple nodes to agree on a single state or value despite potential failures and network partitions. From traditional distributed databases to modern blockchain networks, consensus protocols ensure reliability and consistency in decentralized environments.</p><figure><img src=/images/angry.png width=600></figure><blockquote><p><em>&ldquo;12 Angry Men&rdquo; film shows 12 jurors deciding the future of an 18-year-old boy accused of murder. For a decision to emerge from the room, <strong>unanimity</strong> must be achieved.</em></p></blockquote><p>In this post, I first discuss some problems encountered in centralized systems, then question whether these problems can be solved in distributed systems. I first examine the concept of consensus, then try to answer the question <strong>&ldquo;What is a Consensus Protocol?&rdquo;</strong> Finally, I explain <strong>Classical, Paxos, Nakamoto, and Avalanche Consensus Protocols</strong> in order.</p><h2 id=the-problem-with-centralized-systems>The Problem with Centralized Systems
<a class=heading-link href=#the-problem-with-centralized-systems><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>Let&rsquo;s imagine a system managed by a single person. This system provides a certain service to people. In an ideal world, the place where the customer requests service:</p><ol><li><strong>Error-free</strong> — the requested service is provided as requested</li><li><strong>Attack-resistant</strong> — so the requested service is not interrupted</li><li><strong>Hardware works forever</strong> — the system is available for service at every moment service is requested</li></ol><p>Now let&rsquo;s return to the single-person managed system model, taking into account the ideal service expectations. What can happen to a single-person system? The person running the system:</p><ul><li>May give up providing service</li><li>May not be able to handle heavy load</li><li>May be attacked</li><li>May be injured</li><li>May die</li></ul><p>Each of the above events directly affects the <strong>interruption or cessation</strong> of the requested service.</p><p>Traditional computer systems have also adopted a <strong>single-centered (centralized)</strong> approach. A machine called a server sits in the center of the system and responds to requests from clients. This model is called the <strong>server-client</strong> model. In this model, decisions are made by a single party.</p><figure><img src=/images/database.png alt="Traditional computer systems&rsquo; adopted server-client model" width=600><figcaption><p>Traditional computer systems&rsquo; adopted server-client model</p></figcaption></figure><p>At this point, these questions may come to mind: <em>If a single center cannot meet ideal expectations in the real world, can a multi-centered system approach this achievement? Is a mechanism where data and system security are ensured possible in a multi-centered system?</em></p><p>But there is a very important question that should be asked before these questions:</p><blockquote><p><strong>&ldquo;How can we reach an agreement among machines?&rdquo;</strong></p></blockquote><p>To answer the previous questions, we first need to answer this question.</p><p>This question, first thought about by computer scientists like <em>Leslie Lamport</em> and <em>Barbara Liskov</em> in the 1970s, has given rise to the <strong>consensus</strong> concept, which is the foundation of distributed systems.</p><blockquote><p>In centralized systems, all decisions are made by a single entity. For example, all companies use a centralized <strong>ledger</strong> to record data and transactions. In decentralized systems consisting of many distributed and independent nodes, decisions are made collectively and recorded in <strong>distributed ledgers</strong>.</p></blockquote><h2 id=key-terms>Key Terms
<a class=heading-link href=#key-terms><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ul><li><strong>Node:</strong> Points in a network where data is created, received, and transferred. In blockchain, the basic task of nodes is to validate transactions in the network.</li><li><strong>Distributed Ledger:</strong> A decentralized database managed by multiple participants, therefore multiple nodes.</li></ul><hr><h2 id=what-is-consensus>What is Consensus?
<a class=heading-link href=#what-is-consensus><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p><strong>Consensus</strong> means that distributed nodes in a network agree on a certain state of the network. In the context of blockchain, this means agreeing on <strong>which transaction will be recorded in the block, which block will be added to the chain</strong>.</p><p>For a mechanism to reach consensus, it must have three fundamental properties:</p><ol><li><strong>Termination:</strong> All correct processes must eventually produce an output — must reach a conclusion.</li><li><strong>Agreement:</strong> Every node must give the same decision — all decision outputs must be equal.</li><li><strong>Validity:</strong> Every output (decision) must have been triggered by at least one input.</li></ol><p><strong>A consensus protocol determines <em>how</em> distributed nodes in a network will reach consensus</strong>. In other words, consensus protocols define certain rules that network participants must follow to reach a common agreement.</p><p>A consensus protocol must ensure two important properties under certain conditions:</p><ol><li><strong>Liveness:</strong> Requests from correct clients must eventually be confirmed — all nodes must reach consensus.</li><li><strong>Safety:</strong> If an honest node accepts (or rejects) a transaction, all other honest nodes must make the same decision.</li></ol><blockquote><p>Consensus protocols are not voting protocols. A majority agreement is not sufficient for a network state to be accepted. <strong>All nodes in the network</strong> must reach agreement.</p></blockquote><p>Consensus is the process by which a group of distributed nodes reaches agreement on a single value or state. This is crucial in systems where:</p><ul><li>Multiple nodes need to coordinate</li><li>Network partitions can occur</li><li>Some nodes may fail or behave maliciously</li><li>Consistency must be maintained across the network</li></ul><hr><h2 id=classical-consensus-protocols>Classical Consensus Protocols
<a class=heading-link href=#classical-consensus-protocols><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>Classical consensus protocols are the most researched protocol family since the 1970s. Protocols belonging to this family can be distinguished from others by one fundamental characteristic: <strong>point-to-point communication</strong>. In this type of communication, all nodes communicate with each other to reach a decision. In this part of the article, I will address perhaps the most important protocol in this family: the <strong>pBFT (Practical Byzantine Fault Tolerance)</strong> consensus protocol. I will also briefly mention another protocol in the classical consensus family: <strong>Tendermint Core</strong>.</p><h3 id=pbft-consensus-protocol>pBFT Consensus Protocol
<a class=heading-link href=#pbft-consensus-protocol><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><p>Computer scientists Miguel Castro and Barbara Liskov introduced the pBFT Consensus Protocol in their 1999 paper. The algorithm works smoothly in a network with f Byzantine nodes if there are 2f+1 honest nodes. In other words, for the system to work smoothly, no more than 33% of the network should be malicious.</p><figure><img src=/images/scientist.png alt="Turing Award-winning computer scientist and inventor of the pBFT protocol Barbara Liskov" width=400><figcaption><p>Turing Award-winning computer scientist and inventor of the pBFT protocol Barbara Liskov</p></figcaption></figure><p>The pBFT algorithm can be defined as a distributed state machine in a network — a form of state machine replication. Each node carries the same state. The protocol is designed to work in asynchronous networks.</p><p>pBFT is a more suitable consensus algorithm for networks where participants know each other. In other words, it is preferred to use the pBFT algorithm in permissioned networks.</p><p>The pBFT algorithm basically consists of four stages:</p><ol><li><strong>Client sends a request to the primary (leader) node</strong></li><li><strong>Primary node broadcasts this request to backup nodes</strong></li><li><strong>All nodes query the request and send a response to the client</strong></li><li><strong>Client waits for f+1 identical responses from different nodes</strong> (where f is the maximum number of Byzantine nodes that can exist in the network)</li></ol><figure><img src=/images/prepare.png alt="Normal operation of the pBFT algorithm" width=600><figcaption><p>Normal operation of the pBFT algorithm</p></figcaption></figure><p>In this example, C represents the client, 0 represents the primary node, and 1, 2, and 3 represent the backup nodes. In the scenario in the figure, node 3 is inactive. The operation can be summarized according to our staging above: Request is stage 1, pre-prepare is stage 2, prepare and commit is stage 3, and reply is stage 4.</p><p>I strongly recommend watching this video to those who want to hear about the pBFT Consensus Protocol from Barbara Liskov herself.</p><h3 id=tendermint-core>Tendermint Core
<a class=heading-link href=#tendermint-core><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><p>Tendermint Core is a Byzantine Fault Tolerant (BFT) consensus protocol launched by Jae Kwon in 2014.</p><p>Like the pBFT algorithm, Tendermint Core is resistant to 33% of the network being Byzantine nodes. The fundamental difference that distinguishes Tendermint from pBFT is that nodes called <strong>validators</strong> propose blocks to the network and vote on them. For a block to be processed in the network, it needs to collect 2/3 of the voting power in the network. To be a validator node in the network, participants must lock (stake) a certain amount of their money. Nodes that do not behave honestly are punished.</p><p>In the Tendermint algorithm, only one of the validators proposes a block in each round. Which node will propose a block for a certain round depends on the voting power of the nodes, that is, the money they have locked. He who pays the piper calls the tune.</p><p>To avoid distraction, I&rsquo;m keeping the Tendermint Core title short. I leave the <a href=https://docs.tendermint.com/master/introduction/what-is-tendermint.html class=external-link target=_blank rel=noopener>&ldquo;What is Tendermint?&rdquo; article</a>, which examines Tendermint more extensively in the Tendermint documentation, to interested readers.</p><blockquote><p>In classical consensus protocols, <strong>deterministic finality</strong> is observed. For transactions in the network to be finalized, the approval of all nodes is required.</p></blockquote><hr><h3 id=paxos>Paxos
<a class=heading-link href=#paxos><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><p>The Paxos consensus protocol, whose foundations were laid by Leslie Lamport in 1989 and published as a paper in 1998, satisfies the two conditions (liveness, safety) required for a protocol that I mentioned earlier in the article. In this protocol, every computer in the network communicates with each other to reach a common decision.</p><blockquote><p><em>&ldquo;The Paxos algorithm, when presented in plain English, is very simple.&rdquo;</em> -Leslie Lamport</p></blockquote><p>In Paxos terminology, a node acts as a <strong>proposer</strong> and is responsible for initiating the protocol. The proposer is the node that distributes client requests to the network. In addition to proposers, there are nodes in the network that decide on the transaction proposed by the proposer. These nodes are called <strong>acceptors</strong>. When a majority of acceptors accept the proposed transaction, the Paxos protocol terminates and the proposed value is distributed to nodes called <strong>listeners</strong> who want to see the proposed value. To remain faithful to the original terminology, I will refer to nodes by their English names from now on.</p><blockquote><p>In Paxos, a single node can take on every role. That is, a single node can be both a proposer, acceptor, and listener. Additionally, Paxos nodes are &ldquo;persistent&rdquo;; they do not forget the values they have accepted.</p></blockquote><p><strong>How Does Paxos Work?</strong></p><p>The Paxos algorithm consists of four phases:</p><ol><li><p><strong>Prepare:</strong> The proposer selects proposal number n and sends a prepare request to a majority of acceptor nodes (more than 50%).</p></li><li><p><strong>Promise:</strong> If the number n that the acceptor receives is greater than every proposal number it has previously accepted, it promises (promise) the proposer not to accept any number smaller than n.</p></li><li><p><strong>Accept request:</strong> If the proposer has received promises from a majority of acceptors, it now sends an accept request to all these acceptors by combining its proposal n with message v.</p></li><li><p><strong>Accept:</strong> The acceptor accepts the accept request if it has not promised to a prepare request greater than n before the accept request numbered n. It notifies the proposer and listeners of this operation. A Paxos round (execution) is completed.</p></li></ol><figure><img src=/images/proposer.png alt="Operation of the Paxos algorithm for proposal number = 13, proposal value = &ldquo;paxos&rdquo;" width=600><figcaption><p>Operation of the Paxos algorithm for proposal number = 13, proposal value = &ldquo;paxos&rdquo;</p></figcaption></figure><blockquote><p>In the Paxos algorithm, a &ldquo;leader-replica&rdquo; or &ldquo;commander-lieutenant&rdquo; model is used. The proposer is actually nothing more than the node that distributes the request coming from the client to the network. In this case, the proposer is an acceptor node that exhibits leader characteristics.</p></blockquote><p><strong>In which scenario can the Paxos algorithm fail?</strong></p><p>The scenario where the Paxos algorithm can fail is as follows:</p><p>If two proposers are active in the network at the same time, they can block each other&rsquo;s messages by sending proposals alternately for the highest proposal number. Paxos does not terminate until this problem is resolved. Liveness, one of the two most important properties for consensus protocols, is violated in this scenario. This problem can only be solved when one of the proposers notices the situation and gives the network some time for the other proposer&rsquo;s transaction to be accepted.</p><figure><img src=/images/proposer2.png alt="Loss of liveness property in the network when multiple proposers&rsquo; proposal numbers overlap (inability to finalize transactions)" width=600><figcaption><p>Loss of liveness property in the network when multiple proposers&rsquo; proposal numbers overlap (inability to finalize transactions)</p></figcaption></figure><p>The Paxos protocol is resistant to Byzantine nodes up to half the number of acceptor nodes in the system. In other words, for the protocol to work smoothly, if there are f Byzantine nodes, there must be f+1 honest nodes.</p><p>As the number of acceptor nodes in a network using the Paxos consensus algorithm increases, the time to reach consensus among these nodes increases. Therefore, this protocol is not suitable for infrastructure that will be open to everyone, while it is perfect for a small number of nodes that know each other. In other words, Paxos consensus, like classical consensus, provides higher efficiency in permissioned networks with a small number of nodes.</p><blockquote><p>In the Paxos consensus protocol, <strong>deterministic finality</strong> is observed, as seen in classical consensus protocols.</p></blockquote><p>The Paxos consensus algorithm is very important as it is the first protocol to provide a solution for how to reach agreement in networks containing Byzantine nodes. The points where Paxos and Classical consensus fell short were completed by the Nakamoto Consensus Protocol.</p><hr><h3 id=nakamoto-consensus>Nakamoto Consensus
<a class=heading-link href=#nakamoto-consensus><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><p>The Classical and Paxos consensus protocols we have examined so far were able to successfully answer the question &ldquo;How can we reach agreement among machines?&rdquo; However, these two protocols were insufficient in answering this question:</p><p>&ldquo;How can we reach agreement in a network consisting of many independent machines?&rdquo;</p><p>Satoshi Nakamoto first answered this question in 2009 with the Bitcoin whitepaper he published. The Nakamoto Consensus Protocol*, first mentioned in the Bitcoin whitepaper, is the first Byzantine Fault Tolerant (BFT) blockchain consensus protocol. Nakamoto Consensus is the consensus protocol of many blockchain networks that use proof-of-work mechanisms such as Bitcoin, Ethereum, Monero, and Litecoin.</p><p>*The name Nakamoto Consensus Protocol was given later. No naming is mentioned for the protocol in the Bitcoin whitepaper.</p><p><strong>How is consensus reached in Nakamoto consensus?</strong></p><p>Satoshi explains the operation of Nakamoto consensus in 6 stages:</p><ol><li>New transactions are broadcast to all nodes in the network.</li><li>Each node begins to collect new transactions into a block.</li><li>Each node tries to find a proof-of-work for its own block. Proof-of-work is actually a cryptographic puzzle.</li><li>The first node (leader) that solves this puzzle broadcasts its block to all other nodes.</li><li>If all transactions in this block are valid, other nodes accept this block.</li><li>Nodes show that they have accepted the block by starting to work on the block that will come immediately after that block in the chain.</li></ol><p>In these stages, two elements that are a major part of Nakamoto consensus and complete the consensus together stand out: <strong>Proof of Work</strong> and <strong>Longest Chain Rule</strong>.</p><p><strong>Proof of Work (PoW)</strong></p><p>Proof of work is a sybil resistance mechanism based on participants solving certain mathematical problems to have a say in the network. The basic logic behind creating such a mechanism is to create a network resistant to sybil attacks (attempts to control the network with multiple fake identities). Proof-of-work increases the cost of creating identity in the network with the computational power requirement it brings. Before Bitcoin, there were attempts like Hashcash that used proof-of-work mechanisms. However, what distinguished Bitcoin from past unsuccessful proof-of-work attempts was the longest chain rule used by Nakamoto consensus.</p><p>For more detailed information about sybil resistance mechanisms, you can check out this article. I also recommend checking out this thread that explains the difference between sybil resistance mechanisms and consensus algorithms.</p><p><strong>Longest Chain Rule</strong></p><p>According to the longest chain rule, nodes always accept the longest chain as correct and work to add blocks to that chain.</p><p>Let&rsquo;s try to explain the rule through the visual below:</p><figure><img src=/images/fork.jpeg alt="An example of a fork on the blockchain" width=600><figcaption><p>An example of a fork on the blockchain</p></figcaption></figure><ol><li><p>Let&rsquo;s say one node broadcasts block 6a to the blockchain while another node broadcasts block 6b at the same time. This situation in the network is called a fork.</p></li><li><p>At this moment, some of the remaining nodes in the network receive block 6a first, while the rest receive block 6b first.</p></li><li><p>Nodes start working on whichever block reaches them first, but they keep the other branch in case that branch becomes longer.</p></li><li><p>The equality is broken according to which branch gets a block added first. In our example, let&rsquo;s say the equality is broken in favor of 6a. That is, our chain continues from 6a.</p></li><li><p>In this case, nodes working on 6b stop working on that branch and switch to the 6a branch.</p></li></ol><blockquote><p>This rule enabled Bitcoin to be the first scalable and Byzantine Fault Tolerant blockchain network for a high number of participants. The longest chain rule ensured that network participants trusted the network and created trust among participants.</p></blockquote><p>The Nakamoto consensus algorithm provides networks with <strong>probabilistic finality</strong>, unlike the deterministic finality seen in classical protocols. This means that every block recorded in the blockchain, except the genesis block, can be reversed with a very small probability, even if it&rsquo;s minimal. The reason for this is that point-to-point communication is not established in the network. Nakamoto Consensus uses the gossip protocol. This protocol eliminated the validator node limit found in previous consensus types. It enabled Bitcoin to be a permissionless network.</p><p>Despite the probabilistic finality phenomenon, it is impossible to reverse even a single block in the blockchain in a network consisting of more than half honest nodes. So in a network where sufficient decentralization is achieved, we don&rsquo;t need to worry about our transactions being reversed :)</p><blockquote><p>In Bitcoin, blocks that have 6 blocks after them are considered probabilistically finalized.</p></blockquote><p>In the Nakamoto consensus algorithm, unlike classical consensus, a leader is always selected through proof of work. When multiple leaders emerge, the network forks, but consensus is still reached.</p><p>For those interested, I leave <a href=https://hknylcnsy.medium.com/nakamoto-konsens%c3%bcs-protokol%c3%bc-2577036a1681 class=external-link target=_blank rel=noopener>this article</a> that addresses the similarities between Nakamoto and Paxos consensus algorithms.</p><blockquote><p>Bitcoin is a synchronous network. With the proof-of-work algorithm, a block is found in the network every 10 minutes.</p></blockquote><p>Nakamoto Consensus opened the way for digital currencies and created a revolution in the field of modern cryptography with the solutions it brought to the most fundamental problems in distributed systems.</p><p>Next is the final protocol: the Avalanche Consensus Protocol.</p><hr><h2 id=avalanche-consensus>Avalanche Consensus
<a class=heading-link href=#avalanche-consensus><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>An anonymous team called Team Rocket published a paper titled &ldquo;Snowflake to Avalanche: A Novel Metastable Consensus Protocol Family for Cryptocurrencies&rdquo; in May 2018. This paper introduced a new consensus protocol family to the world: the Snow protocol family.
*While preparing this article, I based it not on the paper published in 2018, but on the more comprehensive version published in August 2020, which could be called &ldquo;Scalable and Probabilistic Leaderless BFT Consensus through Metastability.&rdquo;
The paper defines the Snow protocol family as a &ldquo;leaderless and Byzantine fault-tolerant metastable (semi-stable) consensus protocol family.&rdquo;</p><figure><img src=/images/rocket.jpeg alt="Team Rocket (Pokemon)" width=400><figcaption><p>Team Rocket (Pokemon)</p></figcaption></figure><p>In the Pokemon anime, Team Rocket is the main enemy of Satoshi, the main character of the series.</p><p><strong>What is Snow briefly?</strong></p><p>The Snow protocol family, like Nakamoto Consensus, has adopted the gossip algorithm to facilitate communication in the network. Therefore, the protocol provides probabilistic finality rather than deterministic finality to the network. The network reaching a common decision is achieved through metastable mechanisms and repeated sampling of nodes in the network. Although this definition doesn&rsquo;t make much sense now, it will become clearer as we explain how the protocol works.</p><blockquote><p>The Avalanche protocol is leaderless, unlike Classical, Paxos, and Nakamoto consensus.</p></blockquote><p>Let&rsquo;s remember that one of the main components of Nakamoto consensus is the &ldquo;proof-of-work&rdquo; algorithm. Snow consensus does not contain a sybil resistance mechanism within itself as seen in Nakamoto consensus. The protocol is compatible with all kinds of sybil resistance mechanisms, yet the paper states that the most compatible mechanism is &ldquo;proof-of-stake.&rdquo; With this feature, the Snow protocol family is environmentally friendly, consuming much less energy compared to &ldquo;proof-of-work&rdquo; systems.</p><p>The Snow protocol family consists of four protocols:</p><ul><li><strong>Slush</strong> (Slush)</li><li><strong>Snowflake</strong> (Snowflake)</li><li><strong>Snowball</strong> (Snowball)</li><li><strong>Avalanche</strong> (Avalanche)</li></ul><p>Now let&rsquo;s examine step by step how the protocol transforms from slush to an avalanche.</p><p><strong>Slush</strong></p><p>This is the stage where metastability is defined. The Slush protocol is the most fundamental building block of the Snow protocol family. The protocol is not Byzantine Fault Tolerant (BFT).</p><p>Let&rsquo;s assume that nodes express their decisions in two different colors: red and blue.</p><ol><li><p>A node starts colorless. When a transaction is received from the client, the node updates its color to the color of the message from the client and randomly selects k number of nodes from the network. It sends a query message to this group of nodes. Let&rsquo;s say our k number is 10 in this example. And let&rsquo;s say the node is red.</p></li><li><p>Another colorless node that receives the query message updates its color to the color in the message (red) and starts its own query message. A node that receives the query message but already has a color responds to the message with its own color.</p></li><li><p>The node that initiated the query looks at the responses to the query message it sent. If more than half of the responses, that is, at least 6, are blue, the node updates its color to blue. If red responses are in the majority, it stays red, its initial color.</p></li><li><p>Nodes in the network repeat these steps m times. At the end of m steps, whatever color the node has is now its final decision.</p></li><li><p>Given enough time, all nodes in the network will converge to a single color. In other words, all nodes in the network will reach agreement on a single color.</p></li></ol><blockquote><p>The Slush protocol assumes that the balance between red and blue nodes will be broken at the end of the day. The metastability (semi-stability) property comes from here. The reason why the protocol is not Byzantine Fault Tolerant is that Byzantine nodes in the network can prevent a decision from being made in the network by keeping the system in balance.</p></blockquote><p>Now we need to transform our slush piece into a Byzantine Fault Tolerant snowflake.</p><p><strong>Snowflake</strong></p><p>In Snowflake, a counter is added to Slush. This counter records a node&rsquo;s stability to a certain color and ensures the network is Byzantine Fault Tolerant.</p><ol><li><p>Each node has a counter.</p></li><li><p>The counter resets with every color change. Let&rsquo;s say our node starts colorless and turns red. The counter shows zero in the initial state.</p></li><li><p>After one round of Slush is applied, let&rsquo;s say red decision comes from our node&rsquo;s selected group again. The counter shows 1. One more round and red decision comes again. The counter now shows 2. Our node is now a darker red, more stable.</p></li><li><p>When the counter reaches a predetermined β value, it has made its final decision. There will be no change in either color or stability.</p></li></ol><blockquote><p>❓ <strong>Can&rsquo;t the system return to balance even if it loses balance? In this case, don&rsquo;t transactions terminate?</strong></p></blockquote><blockquote><p>💡 <strong>As the network&rsquo;s decision leans toward the majority, the probability of the decision turning toward the minority decreases exponentially. Once balance is lost even by a very small margin, the probability of the system returning to balance is very low.</strong></p></blockquote><p>Now we need to add memory and confidence to the snowflake to turn it into a snowball.</p><p><strong>Snowball</strong></p><p>Snowball adds confidence counters to the counters in Snowflake.</p><ol><li><p>Nodes increment the confidence counter of the color they receive from each message.</p></li><li><p>If the confidence count for the other color exceeds the confidence count for the current color, the node changes color.</p></li></ol><blockquote><p>Snowball is an improvement to the security in Snowflake. It adds a kind of decision history mechanism to nodes. Nodes remember the decisions they made.</p></blockquote><p>We transform the snowball into an avalanche by adding Directed Acyclic Graphs (DAG).</p><p><strong>Avalanche</strong></p><p>We said that Avalanche is completed by adding Directed Acyclic Graphs (DAG) to the Snowball protocol. Let&rsquo;s first examine what DAG is, then look at how Avalanche combines this with previous protocols.</p><p><strong>What is DAG?</strong></p><p>DAG is a graph representation method used for data modeling in computer science. The representation consists of vertices and edges. DAGs are directed because edges progress in one direction. They are acyclic because edges do not form a cycle, they do not return to the vertex they started from. In DAG structure, each vertex represents a transaction. Vertices do not carry more than one transaction, meaning they do not show a block structure.</p><figure><img src=/images/dag.jpeg alt="A simple model showing Directed Acyclic Graphs" width=400><figcaption><p>A simple model showing Directed Acyclic Graphs</p></figcaption></figure><p>Just as in blockchains a block carries the hash of the previous block, in DAGs each transaction must carry information about the transaction that came before it to be accepted in the network. Let&rsquo;s exemplify from Figure 9: transaction d must point to transaction e that came before it to be approved.</p><p><strong>Sink</strong> (can be translated as &ldquo;pit&rdquo; in Turkish) is the vertex where all edges connected to it point to itself. In Avalanche, there is a single sink vertex. This sink is the genesis vertex of the network, the vertex where the first transaction in the network is located.</p><p><strong>How Avalanche Uses DAG:</strong></p><p>In DAG, a transaction (a vertex) is the child of transactions connected to it that came before it, and the parent of transactions connected to it that come after it.</p><p>The biggest challenge in maintaining DAG is making choices between &ldquo;conflicting transactions.&rdquo; In the context of cryptocurrencies, transactions that spend the same money conflict. Only one of the conflicting transactions must be accepted.</p><p>Avalanche solved this problem by running the Snowball protocol in each conflict set of conflicting transactions. While Snowball uses repeated query systems and counter systems to record the trust votes collected by conflicting transactions separately, Avalanche uses the DAG structure and generations that come after conflicting transactions.</p><ol><li><p>Let&rsquo;s send a T transaction to the network. A node in the network only gives a positive response to the query message coming from T under this condition: T and all previous generation transactions connected to it have succeeded in being the preferred choice in their conflict sets. If more than a certain threshold number of nodes voted positively, our T transaction gains a &ldquo;chit.&rdquo;</p></li><li><p>The total chit count in its own and subsequent generations determines the &ldquo;confidence&rdquo; value of that transaction.</p></li></ol><figure><img src=/images/avalanche.jpeg alt="Visual examining the <chit, confidence> structure in DAG" width=400><figcaption><p>Visual examining the &lt;chit, confidence> structure in DAG</p></figcaption></figure><blockquote><p>Each shaded area in the visual represents a conflicting transaction group. This means that only one transaction from each shaded area is accepted.</p></blockquote><blockquote><p>⚠️ <strong>DAG structures are different from blockchains. Therefore, DAGs cannot execute smart contracts. Avalanche has solved this problem with the Snowman consensus protocol. Snowman can be defined as &ldquo;linear Avalanche.&rdquo; This is because smart contract transactions require strict ordering. Snowman shows a blockchain structure.</strong></p></blockquote><p>In my writing, I first tried to answer the question &ldquo;What is a Consensus Protocol?&rdquo; and then explained the fundamental consensus protocols to date - in order: Classical, Paxos, Nakamoto, and Avalanche.</p><p>See you in the next article.</p><hr><h2 id=references>References
<a class=heading-link href=#references><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ul><li><a href=https://arxiv.org/pdf/1711.03936/ class=external-link target=_blank rel=noopener>Snowflake to Avalanche: A Novel Metastable Consensus Protocol Family for Cryptocurrencies</a></li><li><a href=https://cybersecurity.seas.wustl.edu/ning/paper/consensus19.pdf class=external-link target=_blank rel=noopener>Scalable and Probabilistic Leaderless BFT Consensus through Metastability</a></li><li><a href=https://lamport.azurewebsites.net/pubs/byz.pdf class=external-link target=_blank rel=noopener>The Byzantine Generals Problem</a></li><li><a href=https://lamport.azurewebsites.net/pubs/paxos-simple.pdf class=external-link target=_blank rel=noopener>Paxos Made Simple</a></li><li><a href=https://pmg.csail.mit.edu/papers/osdi99.pdf class=external-link target=_blank rel=noopener>Practical Byzantine Fault Tolerance</a></li><li><a href=https://assets-global.website-files.com/5d80307810123f5ffbb34d6e/6009805681b416f34dcae012_Avalanche%20Consensus%20Whitepaper.pdf class=external-link target=_blank rel=noopener>Avalanche Consensus Whitepaper</a></li><li><a href=https://bitcoin.org/bitcoin.pdf class=external-link target=_blank rel=noopener>Bitcoin: A Peer-to-Peer Electronic Cash System</a></li><li><a href=https://cdn.relayto.com/media/files/LPgoWO18TCeMIggJVakt_tendermint.pdf class=external-link target=_blank rel=noopener>Tendermint: Byzantine Fault Tolerance in the Age of Blockchains</a></li><li><a href=https://dergipark.org.tr/tr/download/article-file/2032732 class=external-link target=_blank rel=noopener>Konsensüs Protokolleri ve Blockchain Teknolojisi</a></li><li><a href=https://www.the-paper-trail.org/post/2009-02-03-consensus-protocols-paxos/ class=external-link target=_blank rel=noopener>Consensus Protocols: Paxos</a></li><li><a href=https://hknylcnsy.medium.com/konsens%c3%bcs-protokolleri-ae1f7269648 class=external-link target=_blank rel=noopener>Konsensüs Protokolleri</a></li><li><a href=https://hknylcnsy.medium.com/avalanche-konsens%C3%BCs-protokol%C3%BC-d6ceea06cec8 class=external-link target=_blank rel=noopener>Avalanche Konsensüs Protokolü</a></li><li><a href=https://blog.itublockchain.com/consensus-ve-blockchain-8a7ae7d72eda class=external-link target=_blank rel=noopener>Konsensüs ve Blockchain</a></li><li><a href=https://academy.binance.com/tr/articles/what-is-a-directed-acyclic-graph-dag-in-cryptocurrency#what-is-a-dag class=external-link target=_blank rel=noopener>What is a Directed Acyclic Graph (DAG) in Cryptocurrency?</a></li><li><a href=https://bitcoinmagazine.com/guides/what-is-nakamoto-consensus-bitcoin class=external-link target=_blank rel=noopener>What is Nakamoto Consensus?</a></li><li><a href="https://www.youtube.com/watch?v=Uj638eFIWg8" class=external-link target=_blank rel=noopener>Barbara Liskov on Practical Byzantine Fault Tolerance</a></li><li><a href="https://www.youtube.com/watch?v=d7nAGI_NZPk" class=external-link target=_blank rel=noopener>Leslie Lamport on Paxos</a></li></ul><hr><p><em>This post builds upon my previous work on consensus protocols and expands it with additional technical details and English translation.</em></p></div><footer><section class=see-also></section></footer></article></section></div><footer class=footer><section class=container>©
2025
memduh
·
Powered by <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/ target=_blank rel=noopener>Coder</a>.</section></footer></main><script src=/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script></body></html>